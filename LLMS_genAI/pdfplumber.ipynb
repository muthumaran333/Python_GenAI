{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d73318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
      "  Using cached pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\muthumaran\\.conda\\envs\\llms\\lib\\site-packages (from pdfplumber) (11.3.0)\n",
      "INFO: pip is looking at multiple versions of pdfplumber to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
      "  Using cached pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached pdfplumber-0.11.3-py3-none-any.whl.metadata (41 kB)\n",
      "  Using cached pdfplumber-0.11.2-py3-none-any.whl.metadata (40 kB)\n",
      "  Using cached pdfplumber-0.11.1-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached pdfplumber-0.11.0-py3-none-any.whl.metadata (39 kB)\n",
      "INFO: pip is still looking at multiple versions of pdfplumber to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached pdfplumber-0.10.4-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting pdfminer.six==20221105 (from pdfplumber)\n",
      "  Using cached pdfminer.six-20221105-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pdfplumber\n",
      "  Using cached pdfplumber-0.10.3-py3-none-any.whl.metadata (38 kB)\n",
      "  Using cached pdfplumber-0.10.2-py3-none-any.whl.metadata (35 kB)\n",
      "  Using cached pdfplumber-0.10.1-py3-none-any.whl.metadata (35 kB)\n",
      "  Using cached pdfplumber-0.10.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached pdfplumber-0.9.0-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting Wand>=0.6.10 (from pdfplumber)\n",
      "  Using cached Wand-0.6.13-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\muthumaran\\.conda\\envs\\llms\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (3.4.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\muthumaran\\.conda\\envs\\llms\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (45.0.5)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\muthumaran\\.conda\\envs\\llms\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\muthumaran\\.conda\\envs\\llms\\lib\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.22)\n",
      "Using cached pdfplumber-0.9.0-py3-none-any.whl (46 kB)\n",
      "Using cached pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "Using cached Wand-0.6.13-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: Wand, pdfminer.six, pdfplumber\n",
      "\n",
      "   ---------------------------------------- 0/3 [Wand]\n",
      "   ------------- -------------------------- 1/3 [pdfminer.six]\n",
      "   ------------- -------------------------- 1/3 [pdfminer.six]\n",
      "   ------------- -------------------------- 1/3 [pdfminer.six]\n",
      "   ---------------------------------------- 3/3 [pdfplumber]\n",
      "\n",
      "Successfully installed Wand-0.6.13 pdfminer.six-20221105 pdfplumber-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "with pdfplumber.open(\"path/to/pdf\") as pdf:\n",
    "    text = pdf.extract_text()\n",
    "    print(text)\n",
    "\n",
    "\n",
    "# used to re`trieve tables and images from the PDF\n",
    "\n",
    "# tables = pdf.extract_table()\n",
    "# print(tables)\n",
    "\n",
    "\n",
    "# images = pdf.get_image()\n",
    "# print(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80853f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page 1 Text ---\n",
      "02 Embeddings\n",
      "02 Embeddings\n",
      "What are Embeddings?\n",
      "Embeddings are dense vector representations of data in a continuous vector space. They capture\n",
      "semantic meaning and contextual relationships by mapping discrete entities (like words, sentences,\n",
      "images, or user behaviors) to points in a multi-dimensional space where similar items are positioned\n",
      "closer together.\n",
      "Unlike traditional sparse representations (like one-hot encoding), embeddings are:\n",
      "Dense: They use a fixed number of dimensions to represent information efficiently\n",
      "Learned: They're derived from data rather than manually engineered\n",
      "Continuous: They exist in a smooth vector space allowing for mathematical operations\n",
      "Semantic: They capture meaningful relationships between entities\n",
      "Real-World Example\n",
      "Consider how we might represent colors. A traditional representation might use discrete RGB values\n",
      "(255, 0, 0) for red. An embedding approach would learn that \"scarlet\" and \"crimson\" should be\n",
      "positioned close to \"red\" in vector space, while \"navy\" and \"azure\" would cluster near \"blue.\" This\n",
      "proximity in the embedding space reflects their semantic similarity.\n",
      "How Embeddings Work\n",
      "Embeddings transform discrete data into continuous vector representations through a process of\n",
      "learning from context and relationships within data.\n",
      "The Training Process\n",
      "1. Initialize: Start with random vectors for each entity (word, image, etc.)\n",
      "2. Define an objective: Create a task where predicting context is required\n",
      "For words: Predict surrounding words (Word2Vec)\n",
      "For sentences: Predict whether one sentence follows another (Sentence-BERT)\n",
      "For images: Predict whether images are similar (CLIP)\n",
      "3. Train: Update embeddings through gradient descent to minimize prediction error\n",
      "4. Extract: The resulting vectors become your embeddings\n",
      "Vector Operations\n",
      "Once trained, embeddings enable powerful vector operations:\n",
      "Similarity: Calculate cosine similarity between vectors to find related items\n",
      "Analogy: Famous example: \"king\" - \"man\" + \"woman\" ≈ \"queen\"\n",
      "Clustering: Group similar entities based on embedding proximity\n",
      "Dimensionality\n",
      "Most embedding models use vectors with dimensions ranging from 100-1024. Higher dimensions can\n",
      "capture more nuanced relationships but require more data to train effectively and more computational\n",
      "resources to use.\n",
      "Real-World Example\n",
      "Nikhil Sharma Page 1\n",
      "\n",
      "--- Page 2 Text ---\n",
      "02 Embeddings\n",
      "Consider a product recommendation system. When a user views a red cotton t-shirt, the system doesn't\n",
      "just recommend identical items. Instead, it:\n",
      "1. Converts the product into its embedding vector\n",
      "2. Finds other products with similar embeddings\n",
      "3. Recommends products that may differ in color or exact style but share underlying characteristics\n",
      "the user might appreciate\n",
      "The system learns these relationships from user behavior patterns rather than explicit rules.\n",
      "Use Cases of Embeddings\n",
      "Natural Language Processing\n",
      "Semantic search: Find documents based on meaning rather than exact keywords\n",
      "Text classification: Categorize documents into topics or sentiment\n",
      "Machine translation: Convert words/sentences between languages\n",
      "Question answering: Understand the intent behind questions\n",
      "Computer Vision\n",
      "Image retrieval: Find visually similar images\n",
      "Face recognition: Match faces across different images\n",
      "Video understanding: Classify actions or scenes\n",
      "Recommender Systems\n",
      "Content-based filtering: Recommend items similar to what users have liked\n",
      "Collaborative filtering: Find users with similar preferences\n",
      "Hybrid approaches: Combine multiple embedding types\n",
      "Graph Analysis\n",
      "Node embeddings: Represent entities in a network\n",
      "Link prediction: Identify potential new connections\n",
      "Community detection: Find clusters of related entities\n",
      "Multimodal Applications\n",
      "Text-to-image generation: Transform text descriptions into visual elements\n",
      "Cross-modal retrieval: Find images matching text queries or vice-versa\n",
      "Real-World Example\n",
      "A healthcare organization might use embeddings to:\n",
      "1. Convert patient medical records to embeddings\n",
      "2. Identify clusters of patients with similar conditions\n",
      "3. For a new patient, quickly find similar historical cases\n",
      "4. Use those similar cases to recommend treatment plans based on what worked previously\n",
      "This approach can find subtle patterns that rule-based systems might miss.\n",
      "Implementing Embeddings with Hugging Face (Free\n",
      "Models)\n",
      "Nikhil Sharma Page 2\n",
      "\n",
      "--- Page 3 Text ---\n",
      "02 Embeddings\n",
      "Text Embeddings\n",
      "Sentence Transformers\n",
      "from sentence_transformers import SentenceTransformer\n",
      "# Load a pre-trained model\n",
      "model = SentenceTransformer('all-MiniLM-L6-v2') # Small, efficient model (384\n",
      "dimensions)\n",
      "# Create embeddings for some text\n",
      "sentences = [\n",
      "\"This patient shows signs of diabetes\",\n",
      "\"The patient exhibits symptoms consistent with diabetes mellitus\",\n",
      "\"This user frequently purchases outdoor equipment\"\n",
      "]\n",
      "embeddings = model.encode(sentences)\n",
      "print(f\"Shape of embeddings: {embeddings.shape}\") # [3, 384]\n",
      "# Calculate similarity between first two sentences (medical) vs third (retail)\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "similarity_matrix = cosine_similarity(embeddings)\n",
      "print(f\"Similarity between sentences 1 and 2: {similarity_matrix[0][1]:.4f}\") #\n",
      "High similarity\n",
      "print(f\"Similarity between sentences 1 and 3: {similarity_matrix[0][2]:.4f}\") #\n",
      "Low similarity\n",
      "Using Transformers Directly\n",
      "from transformers import AutoTokenizer, AutoModel\n",
      "import torch\n",
      "# Load BERT model and tokenizer\n",
      "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
      "model = AutoModel.from_pretrained('bert-base-uncased')\n",
      "# Prepare text\n",
      "text = \"Machine learning is transforming healthcare\"\n",
      "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
      "# Generate embeddings\n",
      "with torch.no_grad():\n",
      "outputs = model(\u0000\u0000inputs)\n",
      "# Use CLS token as sentence embedding\n",
      "embeddings = outputs.last_hidden_state[:, 0, :]\n",
      "print(f\"Embedding shape: {embeddings.shape}\") # [1, 768]\n",
      "Image Embeddings\n",
      "Nikhil Sharma Page 3\n",
      "\n",
      "--- Page 4 Text ---\n",
      "02 Embeddings\n",
      "from transformers import CLIPProcessor, CLIPModel\n",
      "import requests\n",
      "from PIL import Image\n",
      "# Load model and processor\n",
      "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
      "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
      "# Load and process an image\n",
      "url = \"http\u0000\u0000\u0000images.cocodataset.org/val2017/000000039769.jpg\"\n",
      "image = Image.open(requests.get(url, stream=True).raw)\n",
      "inputs = processor(images=image, return_tensors=\"pt\")\n",
      "# Generate image embeddings\n",
      "with torch.no_grad():\n",
      "outputs = model.get_image_features(\u0000\u0000inputs)\n",
      "image_embedding = outputs\n",
      "print(f\"Image embedding shape: {image_embedding.shape}\") # [1, 512]\n",
      "Multimodal Embeddings (Text and Image)\n",
      "from transformers import CLIPProcessor, CLIPModel\n",
      "# Load CLIP model and processor\n",
      "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
      "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
      "# Prepare image and text\n",
      "url = \"http\u0000\u0000\u0000images.cocodataset.org/val2017/000000039769.jpg\"\n",
      "image = Image.open(requests.get(url, stream=True).raw)\n",
      "texts = [\"a photo of a cat\", \"a photo of a dog\"]\n",
      "# Process inputs\n",
      "inputs = processor(text=texts, images=image, return_tensors=\"pt\", padding=True)\n",
      "# Get similarity scores\n",
      "with torch.no_grad():\n",
      "outputs = model(\u0000\u0000inputs)\n",
      "logits_per_text = outputs.logits_per_text # Text-image similarity\n",
      "print(f\"Similarity scores: {logits_per_text}\") # Higher score for correct match\n",
      "Building a Semantic Search System\n",
      "import numpy as np\n",
      "from sentence_transformers import SentenceTransformer\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "# Sample database of documents\n",
      "Nikhil Sharma Page 4\n",
      "\n",
      "--- Page 5 Text ---\n",
      "02 Embeddings\n",
      "documents = [\n",
      "\"Artificial intelligence is revolutionizing healthcare\",\n",
      "\"Machine learning models require significant data for training\",\n",
      "\"Neural networks have multiple layers of computational nodes\",\n",
      "\"Healthcare costs continue to rise in many countries\",\n",
      "\"Data privacy is a major concern in medical applications\"\n",
      "]\n",
      "# Create model and embeddings\n",
      "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "document_embeddings = model.encode(documents)\n",
      "# Function to search documents\n",
      "def semantic_search(query, top_k=2):\n",
      "# Create embedding for the query\n",
      "query_embedding = model.encode([query])\n",
      "# Calculate similarity scores\n",
      "similarity_scores = cosine_similarity(query_embedding, document_embeddings)[0]\n",
      "# Get top results\n",
      "top_indices = np.argsort(similarity_scores)[\u0000 -1][:top_k]\n",
      "# Return results\n",
      "results = []\n",
      "for idx in top_indices:\n",
      "results.append({\n",
      "\"document\": documents[idx],\n",
      "\"score\": similarity_scores[idx]\n",
      "})\n",
      "return results\n",
      "# Example search\n",
      "results = semantic_search(\"AI in medicine\", top_k=2)\n",
      "for i, result in enumerate(results):\n",
      "print(f\"Result {i+1}: {result['document']} (Score: {result['score']:.4f})\")\n",
      "Advanced Concepts in Embeddings\n",
      "Embedding Spaces and Transfer Learning\n",
      "Embeddings trained on one task often transfer well to related tasks. This is because the learned vector\n",
      "space captures fundamental patterns that generalize across domains. A model trained on general\n",
      "English text can often produce useful embeddings for specialized domains like legal or medical text with\n",
      "minimal fine-tuning.\n",
      "Contextual vs. Static Embeddings\n",
      "Early embedding models like Word2Vec produced static embeddings where each word has a single\n",
      "vector regardless of context. Modern transformer-based models generate contextual embeddings where\n",
      "the same word receives different vectors based on surrounding context:\n",
      "Nikhil Sharma Page 5\n",
      "\n",
      "--- Page 6 Text ---\n",
      "02 Embeddings\n",
      "\"The bank denied my loan application.\" → financial meaning\n",
      "\"I sat by the bank of the river.\" → geographical meaning\n",
      "Embedding Visualization\n",
      "Tools like TensorBoard or UMAP allow visualization of high-dimensional embeddings in 2D or 3D space,\n",
      "revealing clusters and relationships:\n",
      "from sklearn.manifold import TSNE\n",
      "import matplotlib.pyplot as plt\n",
      "# Create t-SNE model\n",
      "tsne = TSNE(n_components=2, random_state=42)\n",
      "# Fit and transform embeddings to 2D\n",
      "embeddings_2d = tsne.fit_transform(document_embeddings)\n",
      "# Plot\n",
      "plt.figure(figsize=(10, 8))\n",
      "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
      "# Add labels\n",
      "for i, doc in enumerate(documents):\n",
      "plt.annotate(doc[:20] + \"\u0000\u0000\u0000\", (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
      "plt.title(\"t-SNE visualization of document embeddings\")\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "Fine-tuning Embeddings\n",
      "General-purpose embeddings can be fine-tuned for specific domains:\n",
      "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
      "from torch.utils.data import DataLoader\n",
      "# Create a training dataset of similar and dissimilar pairs\n",
      "train_examples = [\n",
      "InputExample(texts=['diabetes symptoms', 'signs of high blood sugar'],\n",
      "label=0.9),\n",
      "InputExample(texts=['heart disease', 'cardiac condition'], label=0.8),\n",
      "InputExample(texts=['diabetes symptoms', 'car maintenance'], label=0.1)\n",
      "]\n",
      "# Create dataloader\n",
      "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
      "# Load model\n",
      "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
      "# Train with cosine similarity loss\n",
      "Nikhil Sharma Page 6\n",
      "\n",
      "--- Page 7 Text ---\n",
      "02 Embeddings\n",
      "train_loss = losses.CosineSimilarityLoss(model)\n",
      "model.fit(\n",
      "train_objectives=[(train_dataloader, train_loss)],\n",
      "epochs=1,\n",
      "warmup_steps=100\n",
      ")\n",
      "Ethical Considerations\n",
      "Embeddings can inherit and amplify biases present in training data. For example:\n",
      "Word embeddings trained on news articles have shown gender biases (associating \"doctor\" with\n",
      "male terms and \"nurse\" with female terms)\n",
      "Face recognition embeddings have demonstrated racial biases in accuracy rates\n",
      "Mitigation strategies include:\n",
      "Careful dataset curation and balancing\n",
      "Debiasing techniques during or after training\n",
      "Regular auditing of embedding-based systems\n",
      "Transparency about limitations\n",
      "Future Directions\n",
      "Multimodal embeddings: Unified representations across text, images, audio, and video\n",
      "Sparse embeddings: Combining benefits of sparse and dense representations for better\n",
      "interpretability\n",
      "Hierarchical embeddings: Representing information at multiple levels of abstraction\n",
      "Domain-specific architectures: Models optimized for particular fields like chemistry or genomics\n",
      "Embedding compression: Creating smaller, more efficient embeddings for resource-constrained\n",
      "environments\n",
      "Foundation model embeddings: Leveraging increasingly powerful large language models to\n",
      "generate rich, context-aware embeddings\n",
      "Embeddings continue to evolve as a fundamental building block of modern machine learning systems,\n",
      "enabling machines to understand and process information in ways that more closely resemble human\n",
      "conceptual thinking.\n",
      "Nikhil Sharma Page 7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "\n",
    "pdf_path = r\"knowledge-base/02 Embeddings.pdf\"\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page_number, page in enumerate(pdf.pages, start=1):\n",
    "        # Extract text\n",
    "        text = page.extract_text()\n",
    "        print(f\"\\n--- Page {page_number} Text ---\\n{text}\")\n",
    "\n",
    "        # Extract tables\n",
    "        tables = page.extract_tables()\n",
    "        for table_index, table in enumerate(tables, start=1):\n",
    "            print(f\"\\n--- Page {page_number} Table {table_index} ---\")\n",
    "            for row in table:\n",
    "                print(row)\n",
    "\n",
    "        # Extract image metadata (coordinates, width, height)\n",
    "        for image in page.images:\n",
    "            print(f\"\\nImage on page {page_number}: {image}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
