{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386a5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938cef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env file\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found. Please check your .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3711d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Gemini API\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b49b97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-2.5-flash-lite\n"
     ]
    }
   ],
   "source": [
    "# List available models\n",
    "models = genai.list_models()\n",
    "for model in models:\n",
    "    if 'generateContent' in model.supported_generation_methods:\n",
    "        print(model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa2d0a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: **Artificial Intelligence (AI)** is a broad field of computer science dedicated to **creating machines that can perform tasks that typically require human intelligence.**\n",
      "\n",
      "In simpler terms, it's about making computers \"think\" and \"learn\" in ways similar to humans, allowing them to solve problems, understand language, recognize patterns, make decisions, and even create new content.\n",
      "\n",
      "Here's a breakdown of what that means:\n",
      "\n",
      "1.  **Mimicking Human Cognitive Functions:** AI aims to replicate or simulate cognitive abilities such as:\n",
      "    *   **Learning:** Acquiring information and rules for using the information.\n",
      "    *   **Reasoning:** Using rules to reach approximate or definite conclusions.\n",
      "    *   **Problem-solving:** Finding solutions to complex problems.\n",
      "    *   **Perception:** Understanding visual and auditory inputs from the world.\n",
      "    *   **Language Understanding & Generation:** Comprehending and producing human language.\n",
      "    *   **Decision-making:** Choosing the best course of action.\n",
      "\n",
      "2.  **How AI Works (Broadly):**\n",
      "    *   **Data:** AI systems are \"trained\" on vast amounts of data (text, images, sounds, numbers, etc.).\n",
      "    *   **Algorithms:** These are sets of rules or instructions that the AI follows to process data, identify patterns, make predictions, or generate outputs.\n",
      "    *   **Machine Learning (ML):** This is a core subset of AI where systems learn from data *without being explicitly programmed* for every single task. Instead, they identify patterns and make predictions based on the data they've seen.\n",
      "    *   **Deep Learning (DL):** A sub-field of ML that uses \"neural networks\" (inspired by the human brain's structure) with many layers to learn very complex patterns from large datasets. This is behind many recent breakthroughs like image recognition and advanced language models.\n",
      "\n",
      "3.  **Examples of AI in Daily Life:**\n",
      "    *   **Virtual Assistants:** Siri, Alexa, Google Assistant (understanding your voice commands).\n",
      "    *   **Recommendation Systems:** Netflix suggesting movies, Amazon recommending products, Spotify's personalized playlists.\n",
      "    *   **Self-Driving Cars:** Recognizing objects, navigating, and making decisions.\n",
      "    *   **Facial Recognition:** Unlocking your phone, security systems.\n",
      "    *   **Spam Filters:** Identifying and blocking unwanted emails.\n",
      "    *   **Medical Diagnosis:** Assisting doctors in identifying diseases from medical images.\n",
      "    *   **Generative AI:** Tools like ChatGPT (generating text), DALL-E (generating images), and Midjourney (creating art from text descriptions).\n",
      "\n",
      "4.  **Types/Levels of AI:**\n",
      "    *   **Narrow AI (or Weak AI):** This is the AI that exists today. It's designed and trained for a specific task (e.g., playing chess, facial recognition, language translation). It can perform its specific task exceptionally well, often better than humans, but it doesn't have general intelligence or consciousness.\n",
      "    *   **General AI (or Strong AI):** This is hypothetical AI that would possess human-like cognitive abilities across a wide range of tasks, capable of understanding, learning, and applying knowledge to solve any problem. It doesn't exist yet.\n",
      "    *   **Superintelligence:** A hypothetical AI that would far surpass human intelligence in every field, including creativity, general knowledge, and problem-solving. Also purely theoretical.\n",
      "\n",
      "In essence, AI is about empowering machines to perform tasks that we once thought only humans could do, and it's rapidly transforming industries, society, and our daily lives.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid input: 'content' argument must not be empty. Please provide a non-empty value.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mChat ended.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGemini:\u001b[39m\u001b[33m\"\u001b[39m, response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muthumaran\\.conda\\envs\\llms\\Lib\\site-packages\\google\\generativeai\\generative_models.py:564\u001b[39m, in \u001b[36mChatSession.send_message\u001b[39m\u001b[34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    558\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    559\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnsupported configuration: The `google.generativeai` SDK currently does not support the combination of `stream=True` and `enable_automatic_function_calling=True`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    560\u001b[39m     )\n\u001b[32m    562\u001b[39m tools_lib = \u001b[38;5;28mself\u001b[39m.model._get_tools_lib(tools)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m content = \u001b[43mcontent_types\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content.role:\n\u001b[32m    567\u001b[39m     content.role = _USER_ROLE\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\muthumaran\\.conda\\envs\\llms\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:286\u001b[39m, in \u001b[36mto_content\u001b[39m\u001b[34m(content)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_content\u001b[39m(content: ContentType):\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    287\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInvalid input: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument must not be empty. Please provide a non-empty value.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    288\u001b[39m         )\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, Mapping):\n\u001b[32m    291\u001b[39m         content = _convert_dict(content)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input: 'content' argument must not be empty. Please provide a non-empty value."
     ]
    }
   ],
   "source": [
    "# Create a chatbot using Gemini\n",
    "model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "chat = model.start_chat()\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Chat ended.\")\n",
    "        break\n",
    "    response = chat.send_message(user_input)\n",
    "    print(\"Gemini:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e88b8995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muthumaran\\.conda\\envs\\llms\\Lib\\site-packages\\gradio\\chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in .env file.\")\n",
    "\n",
    "# Configure Gemini\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "chat_session = model.start_chat()\n",
    "\n",
    "# Chat function\n",
    "def gemini_chat(message, history):\n",
    "    try:\n",
    "        response = chat_session.send_message(message)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Gradio Chat Interface\n",
    "chatbot_ui = gr.ChatInterface(\n",
    "    fn=gemini_chat,\n",
    "    title=\"💬 Gemini Chatbot\",\n",
    "    description=\"Ask questions powered by Google Gemini 2.5\",\n",
    "    theme=\"soft\",\n",
    "    examples=[\"What is AI?\", \"Summarize the news\", \"Explain quantum computing\"]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_ui.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c705e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muthumaran\\AppData\\Local\\Temp\\ipykernel_25324\\705384598.py:36: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot=gr.Chatbot(height=400),\n",
      "c:\\Users\\muthumaran\\.conda\\envs\\llms\\Lib\\site-packages\\gradio\\chat_interface.py:328: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'tuples', will be used.\n",
      "  warnings.warn(\n",
      "c:\\Users\\muthumaran\\.conda\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py:1054: UserWarning: Expected 1 arguments for function <function gemini_chat at 0x00000284D8D720C0>, received 2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\muthumaran\\.conda\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py:1062: UserWarning: Expected maximum 1 arguments for function <function gemini_chat at 0x00000284D8D720C0>, received 2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\muthumaran\\.conda\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py:1054: UserWarning: Expected 1 arguments for function <function gemini_chat at 0x00000284D8D72160>, received 2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\muthumaran\\.conda\\envs\\llms\\Lib\\site-packages\\gradio\\utils.py:1062: UserWarning: Expected maximum 1 arguments for function <function gemini_chat at 0x00000284D8D72160>, received 2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Check if API key is found\n",
    "if not api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in .env file.\")\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Initialize Gemini model (use available model name)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")  # Use \"gemini-1.5-flash\" or \"gemini-pro\"\n",
    "chat = model.start_chat()\n",
    "\n",
    "# Chat function\n",
    "def gemini_chat(user_input):\n",
    "    if user_input.strip().lower() in [\"exit\", \"quit\"]:\n",
    "        return \"Session Ended. Goodbye!\"\n",
    "    try:\n",
    "        response = chat.send_message(user_input)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Gradio Chat Interface\n",
    "gr.ChatInterface(\n",
    "    fn=gemini_chat,\n",
    "    title=\"🌟 Gemini Chatbot\",\n",
    "    description=\"Ask me anything! Powered by Google Gemini\",\n",
    "    chatbot=gr.Chatbot(height=400),\n",
    "    textbox=gr.Textbox(placeholder=\"Type your question here...\", lines=1),\n",
    "    theme=\"soft\",\n",
    "    examples=[\"What is AI?\", \"Summarize the news\", \"Explain quantum computing\"]\n",
    ").launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
